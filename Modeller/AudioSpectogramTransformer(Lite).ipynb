{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "import seaborn as sns\n",
    "from transformers import ASTForAudioClassification, ASTFeatureExtractor\n",
    "\n",
    "# Load AudioSpectrogramTransformer (Lite) model and feature extractor\n",
    "model_name = \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n",
    "feature_extractor = ASTFeatureExtractor.from_pretrained(model_name)\n",
    "model = ASTForAudioClassification.from_pretrained(model_name)\n",
    "\n",
    "class AudioDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_paths, labels, sr=16000, max_length=16000):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.sr = sr\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        waveform, _ = torchaudio.load(file_path)\n",
    "        waveform = waveform.mean(dim=0)\n",
    "        waveform = waveform[:self.max_length]\n",
    "        waveform = torch.nn.functional.pad(waveform, (0, max(0, self.max_length - len(waveform))))\n",
    "\n",
    "        return waveform, label\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, y_scores, class_idx):\n",
    "    \"\"\"Calculate comprehensive metrics for a specific class\"\"\"\n",
    "    y_true_binary = (y_true == class_idx).astype(int)\n",
    "    y_pred_binary = (y_pred == class_idx).astype(int)\n",
    "    y_scores_binary = y_scores[:, class_idx]\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true_binary, y_pred_binary).ravel()\n",
    "\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    sensitivity = recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    try:\n",
    "        fpr, tpr, _ = roc_curve(y_true_binary, y_scores_binary)\n",
    "        auc_score = auc(fpr, tpr)\n",
    "    except:\n",
    "        auc_score = 0\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'sensitivity': sensitivity,\n",
    "        'specificity': specificity,\n",
    "        'f1_score': f1,\n",
    "        'auc': auc_score\n",
    "    }\n",
    "\n",
    "class ModelAnalyzer:\n",
    "    def __init__(self, class_names):\n",
    "        self.class_names = class_names\n",
    "        self.num_classes = len(class_names)\n",
    "        self.training_history = {'loss': [], 'val_loss': []}\n",
    "        self.epoch_times = []\n",
    "        self.inference_times = []\n",
    "        self.metrics = {\n",
    "            'train': {class_name: {} for class_name in class_names},\n",
    "            'test': {class_name: {} for class_name in class_names}\n",
    "        }\n",
    "\n",
    "    def plot_confusion_matrix(self, y_true, y_pred, title):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=self.class_names,\n",
    "                   yticklabels=self.class_names)\n",
    "        plt.title(f'Confusion Matrix - {title}')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_roc_curves(self, y_true, y_scores):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        y_true_bin = np.eye(self.num_classes)[y_true]\n",
    "\n",
    "        for i, class_name in enumerate(self.class_names):\n",
    "            fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_scores[:, i])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, label=f'{class_name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves for Each Root Note')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_training_history(self):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        epochs = range(1, len(self.training_history['loss']) + 1)\n",
    "        plt.plot(epochs, self.training_history['loss'], 'b-', label='Training Loss')\n",
    "        plt.plot(epochs, self.training_history['val_loss'], 'r-', label='Validation Loss')\n",
    "        plt.title('Training and Validation Loss Over Epochs')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def print_timing_stats(self):\n",
    "        print(\"\\nTiming Statistics:\")\n",
    "        print(f\"Average Training Time per Epoch: {np.mean(self.epoch_times):.2f} seconds\")\n",
    "        print(f\"Average Inference Time per Sample: {np.mean(self.inference_times):.4f} seconds\")\n",
    "\n",
    "    def print_metrics(self, dataset_type):\n",
    "        dataset_key = dataset_type.lower()\n",
    "        print(f\"\\n{dataset_type} Set Metrics:\")\n",
    "        for class_name in self.class_names:\n",
    "            print(f\"\\nMetrics for Root Note {class_name}:\")\n",
    "            metrics = self.metrics[dataset_key][class_name]\n",
    "            for metric_name, value in metrics.items():\n",
    "                print(f\"{metric_name}: {value:.4f}\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "def analyze_root_notes(train_path, test_path, class_names, num_epochs=10):\n",
    "    print(\"Initializing analysis...\")\n",
    "    analyzer = ModelAnalyzer(class_names)\n",
    "\n",
    "    def collect_file_paths_and_labels(path, class_names):\n",
    "        file_paths = []\n",
    "        labels = []\n",
    "\n",
    "        for class_name in class_names:\n",
    "            class_path = os.path.join(path, class_name)\n",
    "            if os.path.exists(class_path):\n",
    "                for file in os.listdir(class_path):\n",
    "                    if file.endswith(\".wav\"):\n",
    "                        file_paths.append(os.path.join(class_path, file))\n",
    "                        labels.append(class_names.index(class_name))\n",
    "\n",
    "        return file_paths, labels\n",
    "\n",
    "    print(\"Creating datasets...\")\n",
    "    train_file_paths, train_labels = collect_file_paths_and_labels(train_path, class_names)\n",
    "    test_file_paths, test_labels = collect_file_paths_and_labels(test_path, class_names)\n",
    "\n",
    "    train_dataset = AudioDataset(train_file_paths, train_labels)\n",
    "    test_dataset = AudioDataset(test_file_paths, test_labels)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    print(\"\\nStarting training simulation...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        train_loss = 1.0 / (epoch + 1)\n",
    "        val_loss = 1.2 / (epoch + 1)\n",
    "\n",
    "        analyzer.training_history['loss'].append(train_loss)\n",
    "        analyzer.training_history['val_loss'].append(val_loss)\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        analyzer.epoch_times.append(epoch_time)\n",
    "\n",
    "        y_true_train = np.random.randint(0, len(class_names), len(train_loader.dataset))\n",
    "        y_pred_train = np.random.randint(0, len(class_names), len(train_loader.dataset))\n",
    "        y_scores_train = np.random.rand(len(train_loader.dataset), len(class_names))\n",
    "\n",
    "        y_true_test = np.random.randint(0, len(class_names), len(test_loader.dataset))\n",
    "        y_pred_test = np.random.randint(0, len(class_names), len(test_loader.dataset))\n",
    "        y_scores_test = np.random.rand(len(test_loader.dataset), len(class_names))\n",
    "\n",
    "        for idx, class_name in enumerate(class_names):\n",
    "            analyzer.metrics['train'][class_name] = calculate_metrics(y_true_train, y_pred_train, y_scores_train, idx)\n",
    "            analyzer.metrics['test'][class_name] = calculate_metrics(y_true_test, y_pred_test, y_scores_test, idx)\n",
    "\n",
    "        inference_start_time = time.time()\n",
    "        # Simulate inference\n",
    "        inference_time = time.time() - inference_start_time\n",
    "        analyzer.inference_times.append(inference_time)\n",
    "\n",
    "    analyzer.print_timing_stats()\n",
    "    analyzer.print_metrics('train')\n",
    "    analyzer.print_metrics('test')\n",
    "    analyzer.plot_roc_curves(y_true_test, y_scores_test)\n",
    "    analyzer.plot_confusion_matrix(y_true_test, y_pred_test, 'Test Set')\n",
    "    analyzer.plot_training_history()\n",
    "\n",
    "# Use your actual dataset paths\n",
    "train_data_path = # Your train_data_path in Google Drive\n",
    "test_data_path = # Your test_data_path in Google Drive\n",
    "class_names = # Your class names with in an array\n",
    "\n",
    "analyze_root_notes(train_data_path, test_data_path, class_names)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
